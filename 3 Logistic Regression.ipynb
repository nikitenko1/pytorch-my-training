{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4287f5d",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 30px;\"> Logistic Regression with PyTorch</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577e27c",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px;\"> Building a Logistic Regression Model with PyTorch</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b0af0",
   "metadata": {},
   "source": [
    "> Steps¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b114ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Dataset\n",
    "# Step 2: Make Dataset Iterable\n",
    "# Step 3: Create Model Class\n",
    "# Step 4: Instantiate Model Class\n",
    "# Step 5: Instantiate Loss Class\n",
    "# Step 6: Instantiate Optimizer Class\n",
    "# Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7b031",
   "metadata": {},
   "source": [
    "> Step 1a: Loading MNIST Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d84fc",
   "metadata": {},
   "source": [
    "> Inspect length of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a854a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:07<00:00, 1.40MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 217kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.27MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631740bc",
   "metadata": {},
   "source": [
    "> Inspecting a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d1bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768df6e8",
   "metadata": {},
   "source": [
    "> Inspecting a single data point in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f380e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71699e2",
   "metadata": {},
   "source": [
    "> Inspecting training dataset first element of tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22dd048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Matrix\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e364ce",
   "metadata": {},
   "source": [
    "> Inspecting training dataset second element of tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dd3536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394db3e",
   "metadata": {},
   "source": [
    "**Displaying MNIST**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378955bd",
   "metadata": {},
   "source": [
    "> Verifying shape of MNIST image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bbb1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "\n",
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00e596",
   "metadata": {},
   "source": [
    "> Plot image of MNIST image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf178a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(show_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e1f3b",
   "metadata": {},
   "source": [
    "> Second element of tuple shows label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3ac00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63457ef5",
   "metadata": {},
   "source": [
    "> Plot second image of MNIST image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36b68f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = train_dataset[1][0].numpy().reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(show_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2edf08",
   "metadata": {},
   "source": [
    "> Second element of tuple shows label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1506502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82334828",
   "metadata": {},
   "source": [
    "> Step 1b: Loading MNIST Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55176fbd",
   "metadata": {},
   "source": [
    "> Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8a55aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f9715",
   "metadata": {},
   "source": [
    "> Test dataset elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74477c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a52289",
   "metadata": {},
   "source": [
    "> Test dataset first element in tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6230e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image matrix\n",
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a55dca2",
   "metadata": {},
   "source": [
    "> Plot image sample from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27164edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(show_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588ee49",
   "metadata": {},
   "source": [
    "> Test dataset second element in tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e2b68cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe7362",
   "metadata": {},
   "source": [
    "> Step 2: Make Dataset Iterable¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2dbaf5",
   "metadata": {},
   "source": [
    "> Recap training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e4b9001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7005a",
   "metadata": {},
   "source": [
    "> Defining epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ea17cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When the model goes through the whole 60k images once, learning how to classify 0-9, it's consider 1 epoch.\n",
    "\n",
    "# However, there's a concept of batch size where it means the model would look at 100 images \n",
    "# before updating the model's weights, thereby learning. When the model updates its weights (parameters) \n",
    "# after looking at all the images, this is considered 1 iteration.\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "# We arbitrarily set 3000 iterations here which means the model would update 3000 times.\n",
    "\n",
    "\n",
    "n_iters = 3000\n",
    "# One epoch consists of 60,000 / 100 = 600 iterations. \n",
    "# Because we would like to go through 3000 iterations, this implies we would have 3000 / 600 = 5 epochs \n",
    "# as each epoch has 600 iterations.\n",
    "\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e410c2ab",
   "metadata": {},
   "source": [
    "> Create Iterable Object: Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e23bc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcc7cf",
   "metadata": {},
   "source": [
    "> Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f5e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "isinstance(train_loader, collections.abc.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403f695",
   "metadata": {},
   "source": [
    "> Create Iterable Object: Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a76db734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterable object\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ecf9b9",
   "metadata": {},
   "source": [
    "> Check iterability of testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b24d237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(test_loader, collections.abc.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f7c89",
   "metadata": {},
   "source": [
    "> Iterate through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a22cd791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "img_1 = np.ones((28, 28))\n",
    "img_2 = np.ones((28, 28))\n",
    "lst = [img_1, img_2]\n",
    "\n",
    "# Need to iterate\n",
    "# Think of numbers as the images\n",
    "for i in lst:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ba748",
   "metadata": {},
   "source": [
    "> Step 3: Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39fc2b",
   "metadata": {},
   "source": [
    "> Create model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27f6d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as linear regression! \n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f0232",
   "metadata": {},
   "source": [
    "> Step 4: Instantiate Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17f7a6",
   "metadata": {},
   "source": [
    "> Check size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32364361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of images\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476bed65",
   "metadata": {},
   "source": [
    "> Istantiate model class based on input and out dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61fc380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we're trying to classify digits 0-9 a total of 10 classes, our output dimension is 10.\n",
    "\n",
    "# And we're feeding the model with 28x28 images, hence our input dimension is 28x28.\n",
    "\n",
    "\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cdbdf",
   "metadata": {},
   "source": [
    "> Step 5: Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4402f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression: Cross Entropy Loss\n",
    "# Linear Regression: MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b69c2c",
   "metadata": {},
   "source": [
    "> Create Cross Entry Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e13d089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33f199",
   "metadata": {},
   "source": [
    "> What happens in nn.CrossEntropyLoss()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93e46e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It does 2 things at the same time.\n",
    "\n",
    "\n",
    "# 1. Computes softmax (logistic/softmax function)\n",
    "# 2. Computes cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04026fea",
   "metadata": {},
   "source": [
    "> Step 6: Instantiate Optimizer Class¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e38b092",
   "metadata": {},
   "source": [
    "* parameters = parameters - learning_rate * parameters_gradients\n",
    "* **At every iteration, we update our model's parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c43b3",
   "metadata": {},
   "source": [
    "> Create optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b611a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f0275",
   "metadata": {},
   "source": [
    "> Parameters In-Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1f0f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000002108DCE18C0>\n",
      "2\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#  You'll realize we have 2 sets of parameters, 10x784 which is A and 10x1 which is b in the  -->\n",
    "#  equation where X is our input of size 784. -->\n",
    "\n",
    "#   We'll go into details subsequently how these parameters interact with our input to produce our 10x1 output. -->\n",
    "\n",
    "\n",
    "# Type of parameter object\n",
    "print(model.parameters())\n",
    "\n",
    "# Length of parameters\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# FC 1 Parameters \n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC 1 Bias Parameters\n",
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c9d4e",
   "metadata": {},
   "source": [
    "> Step 7: Train Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14263428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process\n",
    "# Convert inputs/labels to tensors with gradients\n",
    "# Clear gradient buffets\n",
    "# Get output given inputs\n",
    "# Get loss\n",
    "# Get gradients w.r.t. parameters\n",
    "# Update parameters using gradients\n",
    "# parameters = parameters - learning_rate * parameters_gradients\n",
    "# REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcd7ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8460644483566284. Accuracy: 70.2300033569336\n",
      "Iteration: 1000. Loss: 1.588952898979187. Accuracy: 77.44000244140625\n",
      "Iteration: 1500. Loss: 1.3307206630706787. Accuracy: 79.95999908447266\n",
      "Iteration: 2000. Loss: 1.170548677444458. Accuracy: 81.43000030517578\n",
      "Iteration: 2500. Loss: 1.0122350454330444. Accuracy: 82.33000183105469\n",
      "Iteration: 3000. Loss: 1.075974702835083. Accuracy: 83.16000366210938\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba025d",
   "metadata": {},
   "source": [
    "> Printing outputs of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55472e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([[-3.9065e-01, -1.4185e+00, -4.7778e-01, -1.5559e-01, -2.0090e-02,\n",
      "         -4.4000e-01, -1.0299e+00,  2.8613e+00, -3.2124e-01,  8.2123e-01],\n",
      "        [ 2.9404e-01, -9.4812e-02,  1.4889e+00,  9.4816e-01, -1.6315e+00,\n",
      "          7.2761e-01,  1.3104e+00, -1.8209e+00,  2.4303e-01, -1.5134e+00],\n",
      "        [-8.8933e-01,  2.4136e+00,  3.1521e-01,  1.3154e-01, -6.9698e-01,\n",
      "         -3.3509e-01, -1.5599e-01, -2.8889e-01,  2.5825e-01, -2.4154e-01],\n",
      "        [ 2.8120e+00, -2.5491e+00, -1.0284e-01, -3.3489e-01, -8.7168e-01,\n",
      "          4.2231e-01,  1.1221e+00,  3.7884e-01, -5.5959e-01, -3.3561e-01],\n",
      "        [ 6.4506e-02, -2.1144e+00,  3.8825e-01, -7.2359e-01,  1.8090e+00,\n",
      "         -4.4858e-01,  2.7836e-01,  3.4893e-01, -3.3542e-02,  1.0255e+00],\n",
      "        [-1.3254e+00,  2.9122e+00,  1.9906e-01,  1.8081e-01, -8.1286e-01,\n",
      "         -4.0264e-01, -6.8161e-01, -1.2296e-01,  5.0249e-01, -1.5976e-01],\n",
      "        [-1.3262e+00, -1.2161e+00, -8.1914e-01,  4.4076e-01,  1.6830e+00,\n",
      "          2.7889e-01, -6.8235e-01,  7.8622e-01,  6.4651e-01,  8.9858e-01],\n",
      "        [-1.1213e+00, -4.0831e-01, -6.9688e-01, -6.6221e-02,  1.0155e+00,\n",
      "          3.5273e-01,  2.4969e-01, -1.3713e-01, -2.9107e-02,  1.3204e+00],\n",
      "        [ 4.0505e-01, -4.4277e-01,  1.0034e+00, -1.2602e+00,  4.9207e-01,\n",
      "          3.0600e-01,  9.0817e-01, -7.5929e-01,  3.3092e-01,  5.2257e-02],\n",
      "        [-7.2705e-01, -1.1198e+00, -1.1739e+00, -1.1736e+00,  1.1426e+00,\n",
      "         -8.8213e-02, -4.9467e-01,  1.7521e+00,  5.4016e-03,  1.6882e+00],\n",
      "        [ 3.1536e+00, -1.8053e+00,  5.5592e-01,  1.0530e+00, -1.0217e+00,\n",
      "          1.1693e+00, -4.4277e-01, -1.4093e+00,  4.7296e-01, -1.3996e+00],\n",
      "        [ 7.4791e-01, -3.8856e-01,  5.2584e-01,  1.3287e-01,  7.0368e-02,\n",
      "         -4.8633e-01,  6.5540e-01, -1.1211e+00,  3.8833e-01, -4.8419e-01],\n",
      "        [-8.4304e-01, -1.6127e+00, -8.2777e-01, -1.0354e+00,  1.6467e+00,\n",
      "         -2.4077e-02, -2.5592e-01,  9.9634e-01,  2.5431e-01,  2.2070e+00],\n",
      "        [ 3.0710e+00, -2.4991e+00, -2.7181e-01, -3.6134e-01, -3.5892e-01,\n",
      "          7.2576e-01, -2.8290e-01, -5.0744e-01,  5.0298e-01,  2.1258e-01],\n",
      "        [-1.4295e+00,  2.6389e+00, -1.9998e-01,  3.6525e-01, -1.1202e+00,\n",
      "         -2.2912e-01, -2.8806e-01, -1.6945e-01,  2.9949e-01, -2.4976e-01],\n",
      "        [ 6.1183e-01, -8.5946e-01, -1.5904e-01,  1.2860e+00, -1.6337e-01,\n",
      "          8.4976e-01, -3.5900e-01, -4.1284e-01,  4.2928e-01, -5.6539e-01],\n",
      "        [-3.7533e-01, -2.1554e+00, -2.1002e-02, -6.3367e-01,  1.3844e+00,\n",
      "         -5.8681e-01, -3.4167e-01,  8.0959e-01,  3.8307e-02,  1.6666e+00],\n",
      "        [-3.2289e-02, -1.7758e+00, -7.1145e-01,  6.1634e-01, -3.4483e-01,\n",
      "         -4.0075e-01, -7.9452e-01,  2.7897e+00, -4.9529e-01,  3.5238e-01],\n",
      "        [-6.5602e-01, -3.3532e-01, -1.2506e-01,  1.1784e+00, -4.7020e-01,\n",
      "          2.1422e-01,  9.5319e-01, -4.9618e-01, -4.8422e-02, -4.3180e-01],\n",
      "        [-8.5903e-01, -1.4952e+00, -5.1322e-01, -1.0119e-01,  2.0321e+00,\n",
      "          1.3956e-01, -9.0837e-02,  7.3577e-02, -7.0434e-02,  1.4415e+00],\n",
      "        [-1.0041e+00, -4.0646e-01, -1.4547e+00, -1.1630e-01,  5.2186e-01,\n",
      "          2.6551e-01, -1.2810e+00,  1.6216e+00,  2.0659e-01,  1.4957e+00],\n",
      "        [-5.9189e-01, -1.2572e+00,  7.1113e-03,  3.9121e-01,  3.7502e-01,\n",
      "          4.7977e-01,  2.2549e+00, -1.3372e+00,  1.6550e-01,  1.4561e-01],\n",
      "        [-5.5013e-01,  2.7714e-01,  3.9690e-01, -4.2857e-01,  8.2800e-01,\n",
      "         -1.2441e+00,  1.1318e+00,  6.1065e-02,  1.0799e-02, -2.3869e-01],\n",
      "        [-1.7486e-02, -1.0077e+00, -4.7740e-01,  4.4936e-01, -3.5822e-01,\n",
      "          1.4021e+00,  3.2651e-01, -1.0500e+00,  7.7991e-01,  8.0139e-02],\n",
      "        [-6.5944e-01, -1.0666e+00, -1.4112e-02, -1.7156e-01,  1.4845e+00,\n",
      "         -1.5059e-01, -1.7990e-01,  3.0459e-01, -3.6243e-01,  1.0978e+00],\n",
      "        [ 4.1249e+00, -2.6888e+00,  6.9075e-01, -1.0516e+00, -5.4130e-01,\n",
      "          8.5886e-01,  1.0594e+00, -7.1744e-01, -1.2291e-01, -1.4037e+00],\n",
      "        [ 3.2799e-02, -1.3489e+00, -3.4968e-01,  3.2605e-02,  4.2425e-01,\n",
      "         -6.5266e-02, -4.6286e-01,  1.9130e+00, -2.8161e-01,  1.0496e+00],\n",
      "        [-3.7415e-01, -2.0620e+00, -2.6060e-01, -7.6820e-01,  2.3091e+00,\n",
      "          1.9536e-01,  2.6213e-01, -1.6511e-01,  1.3308e-01,  1.5732e+00],\n",
      "        [ 2.6923e+00, -2.4491e+00, -9.1598e-03,  8.0749e-01, -1.2790e+00,\n",
      "          5.8967e-01, -1.8173e-01, -5.5023e-01,  6.5434e-01, -6.3799e-01],\n",
      "        [-1.3181e+00,  1.5303e+00, -2.3008e-01,  2.3971e-01, -4.3179e-01,\n",
      "          2.5086e-01,  1.5500e-01, -1.3670e-01,  3.8628e-01, -2.9638e-01],\n",
      "        [-1.0622e+00, -2.6508e-01, -1.1489e+00,  2.2928e+00, -1.3393e+00,\n",
      "          5.8391e-01, -4.3222e-01,  3.8609e-01, -8.7811e-02,  9.8321e-02],\n",
      "        [-1.0806e+00,  1.1350e+00, -4.4616e-01,  3.9433e-01, -2.4588e-01,\n",
      "          4.1404e-02, -2.1217e-01,  3.6482e-02,  2.1324e-03,  1.6049e-01],\n",
      "        [-1.0285e+00, -7.9748e-01, -6.8709e-01,  2.2713e+00, -1.7346e-01,\n",
      "          1.2589e+00, -3.0239e-01, -9.3384e-01,  2.9856e-01, -4.1418e-02],\n",
      "        [ 1.8194e+00, -1.4320e+00,  8.7588e-01, -1.7300e+00,  6.4860e-01,\n",
      "          8.3492e-02,  1.7496e+00, -8.4084e-01, -2.6479e-01, -2.3756e-01],\n",
      "        [-9.0998e-01, -4.4947e-01,  6.8251e-01, -3.4505e-01, -2.8013e-01,\n",
      "         -3.8170e-01, -1.3591e+00,  1.6664e+00,  7.8869e-01,  5.8022e-01],\n",
      "        [ 5.0387e-01, -1.1431e+00,  2.4249e+00,  4.6384e-01, -7.9017e-01,\n",
      "          1.3700e-01,  2.2742e-01, -3.5131e-01,  3.6072e-01, -1.6692e+00],\n",
      "        [-5.7750e-01, -1.6344e+00,  1.3314e-01,  7.2591e-02,  7.5246e-03,\n",
      "         -3.3463e-01, -5.2895e-01,  2.3405e+00, -2.8393e-01,  8.8490e-01],\n",
      "        [-1.4891e+00,  2.1400e+00, -4.7077e-01,  9.7894e-02, -4.9476e-01,\n",
      "          1.5442e-02, -2.0270e-01,  5.1185e-02,  4.3502e-01, -4.3649e-02],\n",
      "        [ 2.1988e-01,  4.4418e-01,  7.4405e-01,  1.2452e+00, -2.0719e+00,\n",
      "          1.9825e-01,  4.7527e-01, -1.2486e+00,  5.5496e-01, -1.1860e+00],\n",
      "        [-1.6025e+00,  2.9794e+00, -1.9658e-01,  3.5075e-01, -1.2495e+00,\n",
      "         -1.5734e-01, -3.1155e-01, -5.7075e-01,  6.6276e-01, -3.2767e-01],\n",
      "        [-6.6833e-01,  1.6225e+00,  8.7468e-02, -1.2155e-02, -5.3089e-01,\n",
      "         -1.1247e-01, -5.7164e-02, -1.3806e-01,  9.7431e-02, -1.8114e-01],\n",
      "        [-8.2815e-01, -9.6215e-01, -8.5394e-03, -4.1585e-01,  9.6893e-02,\n",
      "         -1.2063e-01, -4.6282e-01,  2.0368e+00, -2.9123e-01,  1.2407e+00],\n",
      "        [-2.0978e+00, -3.7679e-01, -2.5687e-01, -1.8442e-01,  2.3367e+00,\n",
      "         -4.8462e-01, -8.9903e-01,  6.0946e-01,  5.2345e-01,  1.7069e+00],\n",
      "        [-5.4693e-01,  9.3710e-01,  1.2793e+00, -9.3172e-02, -2.0668e-01,\n",
      "         -4.9553e-01,  2.0590e-01, -1.2705e+00,  3.4081e-01, -5.6000e-01],\n",
      "        [-1.2333e+00, -1.3713e-01, -7.7109e-03,  1.3686e+00, -6.7728e-01,\n",
      "          3.4636e-01,  3.4911e-01, -2.3128e-01, -7.5609e-02, -2.5823e-01],\n",
      "        [ 2.1230e-02, -1.1991e+00, -4.9796e-01,  1.6339e+00, -5.6806e-01,\n",
      "          1.3577e+00,  6.3176e-03, -1.2521e+00,  7.2768e-01, -5.5579e-01],\n",
      "        [-1.7050e+00,  2.9795e-01,  1.2909e-02,  8.6246e-01, -1.1795e-01,\n",
      "          1.4805e-01,  1.2101e-01, -4.1819e-02,  1.8308e-01,  3.7645e-01],\n",
      "        [-7.8481e-01, -4.4406e-01,  1.6170e+00, -3.5816e-01,  6.0671e-01,\n",
      "         -3.6116e-01,  6.2593e-01, -2.2954e-01,  2.2370e-02,  1.2610e-01],\n",
      "        [-1.0967e+00, -2.5602e+00, -1.2724e+00,  4.5834e-02,  2.9525e+00,\n",
      "          4.3555e-01, -5.8680e-01,  3.1111e-01,  7.6101e-01,  2.3206e+00],\n",
      "        [-5.6785e-01, -2.1124e+00,  3.9014e-01, -7.9298e-01,  2.4308e+00,\n",
      "         -8.2199e-01,  4.0452e-01,  3.5123e-01, -2.1614e-01,  9.8286e-01],\n",
      "        [-7.7873e-02, -1.0337e+00,  1.9786e-01,  1.7445e-01, -4.0565e-01,\n",
      "          4.6891e-01,  2.1758e+00, -1.1708e+00, -2.0050e-01, -6.5371e-01],\n",
      "        [-3.9770e-02, -8.4997e-01, -2.8400e-01,  1.8327e+00, -7.4490e-01,\n",
      "          5.4193e-01,  1.0157e-01, -3.0029e-01, -3.4561e-01,  5.0503e-02],\n",
      "        [ 5.7760e-01, -1.2191e+00, -1.3709e+00,  1.4131e-01,  6.7539e-01,\n",
      "          1.3233e+00,  3.3268e-02, -3.0568e-01,  4.9954e-02,  6.6389e-01],\n",
      "        [ 1.3817e-01, -9.5185e-01, -2.3886e-01,  9.7530e-01, -1.0452e-01,\n",
      "          6.5907e-01, -2.2399e-01, -5.4859e-01,  3.0490e-01, -3.6288e-01],\n",
      "        [ 8.4411e-02, -5.7927e-01,  1.4223e+00, -2.5153e-01,  5.5366e-01,\n",
      "         -8.4081e-01,  1.0600e+00, -7.2463e-01,  4.8552e-02, -4.3184e-01],\n",
      "        [ 1.4887e+00, -2.4156e+00, -6.5232e-01,  3.5881e-01, -6.9869e-01,\n",
      "          8.4205e-01,  4.0897e-01, -8.2892e-01,  1.1713e+00, -5.5886e-01],\n",
      "        [-7.7529e-03, -2.5928e+00, -1.5271e-01, -2.9800e-01,  2.6875e+00,\n",
      "         -1.1920e-02,  3.7997e-01, -4.2311e-01,  1.0694e-02,  9.8600e-01],\n",
      "        [-8.6679e-01,  2.4536e+00,  1.2190e-01,  1.7899e-01, -9.2643e-01,\n",
      "         -2.7791e-01, -4.6287e-01, -2.3621e-01,  3.5938e-01, -1.3762e-01],\n",
      "        [-2.0201e-01, -1.8739e+00, -1.0824e+00, -7.7778e-01,  1.8910e+00,\n",
      "         -3.2238e-01, -5.5973e-02,  1.0331e+00, -1.6284e-01,  2.0659e+00],\n",
      "        [ 4.2365e-02,  3.4419e-01, -6.2188e-01, -4.5878e-01,  2.5567e-01,\n",
      "          4.8456e-01, -1.6579e-01,  4.5675e-01, -4.3657e-02, -1.0410e-01],\n",
      "        [-1.1396e-02, -1.7151e+00, -7.1723e-01,  6.8655e-01,  2.5161e-01,\n",
      "         -5.8174e-02, -3.6014e-02,  2.1020e+00, -4.7299e-01,  5.1773e-01],\n",
      "        [ 2.3865e-01, -8.4759e-01,  1.0599e+00, -1.6402e+00, -1.8895e-01,\n",
      "          8.0522e-02,  5.5755e-01, -8.8935e-01,  1.1212e+00,  1.8093e-01],\n",
      "        [-8.5443e-01, -7.3109e-01, -7.5751e-02, -2.9105e-01,  7.0699e-01,\n",
      "          2.2873e-01,  1.3484e-01, -1.2530e-01,  3.5229e-01,  1.1065e+00],\n",
      "        [-1.0378e+00, -3.1989e-01,  1.2022e+00,  5.6249e-01, -1.5871e-01,\n",
      "         -1.9502e-01, -3.9065e-01, -7.5172e-01,  2.9203e-01,  9.2405e-02],\n",
      "        [-1.1282e+00, -8.5122e-01,  3.5260e-01, -5.0071e-01,  5.6226e-01,\n",
      "         -5.1181e-01, -3.1035e-01,  1.4472e+00,  7.4139e-02,  6.5835e-01],\n",
      "        [-1.2896e+00, -5.3690e-01, -5.7070e-01,  4.7958e-01,  5.0709e-01,\n",
      "          4.5761e-01,  1.2382e-01, -3.9174e-01,  3.4348e-01,  8.5137e-01],\n",
      "        [ 2.7323e-01, -1.7696e-01,  7.4751e-01, -4.4152e-02,  3.3491e-01,\n",
      "         -8.2103e-01,  5.1293e-01,  1.0665e-01, -3.1073e-01, -6.0900e-01],\n",
      "        [-2.8175e-01, -1.4390e+00,  5.4847e-01, -1.0231e+00,  2.1747e+00,\n",
      "         -7.3158e-01, -2.0343e-01,  3.7310e-01,  3.4187e-01,  6.5410e-01],\n",
      "        [-1.5562e+00, -5.1324e-01, -4.0120e-01,  2.6041e+00, -5.7464e-01,\n",
      "          8.4485e-01, -8.9473e-01, -9.2188e-01,  9.4433e-01,  1.6562e-02],\n",
      "        [ 2.7839e+00, -1.3143e+00,  8.2512e-01, -7.4500e-01, -1.5115e+00,\n",
      "          8.0611e-01,  4.3943e-01, -1.0347e-01, -1.2986e-01, -4.7872e-01],\n",
      "        [ 3.4449e-01, -1.6544e+00, -7.7538e-01,  5.9150e-02, -2.5463e-01,\n",
      "         -5.9386e-01, -6.9812e-01,  2.8602e+00, -3.9308e-01,  3.2104e-01],\n",
      "        [ 4.4158e+00, -2.4888e+00,  1.0215e+00,  2.8754e-01, -1.2766e+00,\n",
      "          1.2386e+00,  1.6731e-01, -1.3769e+00,  4.2347e-01, -1.2525e+00],\n",
      "        [ 1.2674e+00, -1.3056e+00,  1.7605e+00,  1.5471e+00, -1.3237e+00,\n",
      "         -1.3647e-01,  5.1295e-01, -8.6932e-01,  2.4657e-01, -2.1897e+00],\n",
      "        [-1.3639e+00,  6.0566e-01,  5.9404e-02, -2.3858e-01, -9.2254e-01,\n",
      "         -4.6136e-01, -9.5405e-01,  7.3839e-01,  1.3027e+00,  5.6857e-01],\n",
      "        [-1.4390e+00,  2.2718e+00, -4.9825e-01,  8.8589e-03, -9.2072e-01,\n",
      "         -3.0206e-02, -1.5802e-01, -4.7193e-02,  5.7455e-01, -1.9332e-01],\n",
      "        [-1.8448e+00,  6.0093e-01, -6.0303e-01, -5.1329e-01,  1.0510e+00,\n",
      "         -6.2804e-01, -8.9429e-01,  1.7515e+00,  2.0551e-01,  6.8857e-01],\n",
      "        [-4.8176e-01,  2.3234e-01, -3.8806e-01,  2.2238e+00, -9.9421e-01,\n",
      "          9.3174e-01, -4.7404e-01, -1.0748e+00,  3.3938e-01, -7.9518e-01],\n",
      "        [-8.0897e-01, -3.7745e-01,  7.8504e-01, -6.3121e-01, -1.7351e-01,\n",
      "         -3.2297e-01, -3.6514e-02,  1.8204e+00, -2.5421e-01,  5.6211e-01],\n",
      "        [-1.5946e+00,  1.0383e+00, -7.5090e-01, -3.5786e-02, -1.3225e-01,\n",
      "          4.7890e-02, -5.3414e-01,  4.3033e-01,  8.6758e-01,  6.6353e-01],\n",
      "        [-4.9318e-01, -9.2752e-01, -9.1791e-01, -1.2438e+00,  2.7807e-02,\n",
      "         -3.1956e-01, -1.2997e+00,  3.3940e+00,  3.6313e-01,  8.3619e-01],\n",
      "        [-4.1711e-01, -1.7568e+00, -1.1070e+00, -3.0295e-01,  1.0439e+00,\n",
      "          5.3029e-01, -2.1560e-01,  1.5448e+00, -5.7234e-01,  1.9345e+00],\n",
      "        [-9.9856e-02, -1.7609e+00,  4.9690e-01, -4.6905e-01,  2.0013e-02,\n",
      "          1.9673e-01,  2.2010e+00, -5.6932e-01, -2.6622e-01,  6.3444e-02],\n",
      "        [-4.4420e-01, -1.1261e+00,  3.9541e+00, -3.4711e-01, -1.7202e-01,\n",
      "         -1.0461e+00,  9.6972e-01, -9.0793e-01,  6.0307e-01, -1.2960e+00],\n",
      "        [-4.7274e-01, -1.7396e+00, -5.6665e-01, -1.3469e-01,  8.3033e-01,\n",
      "         -6.4211e-02, -7.7887e-01,  2.1032e+00, -2.0179e-01,  1.6179e+00],\n",
      "        [-6.5068e-01, -7.9675e-02, -3.1799e-01, -1.4975e-01,  7.8299e-01,\n",
      "          8.4376e-01, -5.3800e-01, -6.7736e-01,  1.3852e+00,  5.2306e-01],\n",
      "        [-1.0097e+00, -2.2820e+00, -8.0795e-01,  2.8435e-01,  2.9703e+00,\n",
      "          3.7974e-01, -3.2492e-03, -4.1120e-01,  4.8988e-01,  1.4563e+00],\n",
      "        [-1.7211e+00,  4.2280e-01, -3.7280e-01, -6.3952e-01, -1.6780e-01,\n",
      "         -7.3712e-01, -1.1272e+00,  3.0470e+00,  3.8009e-01,  1.1066e+00],\n",
      "        [-1.3513e-01, -1.5476e+00, -1.3421e+00,  1.6192e+00, -2.1184e-01,\n",
      "          1.0514e+00,  5.5845e-01, -3.2711e-01, -1.5324e-01,  2.5007e-02],\n",
      "        [-1.0198e-01, -1.8570e+00,  8.4963e-01, -8.3302e-01,  1.2649e+00,\n",
      "         -3.9081e-01,  2.6473e+00, -1.2737e-02, -3.3203e-01,  3.5450e-01],\n",
      "        [-1.7064e+00,  3.0747e+00,  4.8759e-01,  1.2665e-01, -7.5676e-01,\n",
      "         -4.1276e-01, -3.9415e-01, -3.9370e-01,  5.8091e-01, -4.2408e-01],\n",
      "        [ 1.8060e-01, -6.8306e-01, -1.9502e-01,  2.5876e+00, -1.4540e+00,\n",
      "          8.5852e-01, -1.4221e+00, -5.1736e-01,  5.7599e-01, -8.3885e-01],\n",
      "        [-1.0739e+00, -5.0040e-01,  2.8211e-01, -6.6657e-01,  1.9353e-01,\n",
      "         -3.4361e-01,  2.7064e+00, -1.0396e+00,  2.1468e-01,  3.5263e-02],\n",
      "        [-8.3903e-01,  1.6204e-01,  1.5538e-01, -5.3746e-01,  5.9135e-01,\n",
      "          1.6669e-02,  1.0490e-02, -1.5240e-01,  6.0449e-01,  4.6660e-01],\n",
      "        [-9.7601e-01, -8.4001e-01, -9.5778e-01,  2.4682e+00, -1.4484e+00,\n",
      "          8.5141e-01, -1.1993e+00,  6.1568e-01,  4.2298e-01,  8.5328e-03],\n",
      "        [-2.2599e+00,  1.9135e+00, -1.4236e-01,  2.3988e-01, -6.4139e-01,\n",
      "         -9.1478e-02,  1.5368e-01, -3.1664e-01,  8.0268e-01,  9.7046e-03],\n",
      "        [-8.3794e-01, -3.2229e-01, -3.8243e-01, -1.0688e+00,  2.2921e+00,\n",
      "         -7.4745e-01,  3.2536e-01,  1.5253e-01,  2.5186e-01,  1.3601e+00],\n",
      "        [-1.1326e+00,  5.6139e-01, -5.2677e-01,  3.6198e-01, -1.7596e-01,\n",
      "          9.8826e-03, -6.4035e-02,  5.7564e-02,  2.0059e-01,  3.6278e-01],\n",
      "        [-2.0389e+00,  1.4329e+00, -8.6159e-01,  2.8347e-01, -3.1610e-01,\n",
      "         -1.9719e-01, -2.4542e-01,  7.1633e-01,  1.8314e-01,  4.7449e-01],\n",
      "        [ 8.1876e-01, -1.0649e+00,  8.9709e-01, -6.9885e-01, -2.9607e-01,\n",
      "          5.1163e-01,  2.0938e+00, -1.0283e+00,  2.1393e-01, -6.0565e-01],\n",
      "        [-1.1222e+00, -1.7706e+00,  3.1385e-02, -7.0628e-01,  1.6635e+00,\n",
      "         -8.9856e-01, -3.4006e-01,  8.6028e-01,  1.7860e-01,  2.3032e+00]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# As we've trained our model, we can extract the accuracy calculation portion to understand \n",
    "# what's happening without re-training the model.\n",
    "\n",
    "# This would print out the output of the model's predictions on your notebook.\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774318af",
   "metadata": {},
   "source": [
    "> Printing output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ca66625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "# This produces a 100x10 matrix because each iteration has a batch size of 100 and each prediction across the 10 classes, \n",
    "# with the largest number indicating the likely number it is predicting.\n",
    "\n",
    "\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs.size())\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f2767",
   "metadata": {},
   "source": [
    "> Printing one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8e7e1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([-0.3907, -1.4185, -0.4778, -0.1556, -0.0201, -0.4400, -1.0299,  2.8613,\n",
      "        -0.3212,  0.8212], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This would be a 1x10 matrix where the largest number is what the model thinks the image is. \n",
    "# Here we can see that in the tensor, position 7 has the largest number, indicating the model thinks the image is 7.\n",
    "\n",
    "# number 0: -0.4181\n",
    "# number 1: -1.0784\n",
    "# ...\n",
    "# number 7: 2.9352  \n",
    "\n",
    "\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs[0, :])\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981878fd",
   "metadata": {},
   "source": [
    "> Printing prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6a30c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecfed6",
   "metadata": {},
   "source": [
    "> Print prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9761f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# We are printing our prediction which as verified above, should be digit 7.\n",
    "\n",
    "\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc505829",
   "metadata": {},
   "source": [
    "> Print prediction, label and label size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a65093a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7)\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 0\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])\n",
    "\n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "\n",
    "        print('LABEL FOR IMAGE 0')\n",
    "        print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e3771",
   "metadata": {},
   "source": [
    "> Print second prediction and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57527d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(2)\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 1\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[1])\n",
    "\n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "\n",
    "        print('LABEL FOR IMAGE 1')\n",
    "        print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e683734",
   "metadata": {},
   "source": [
    "> Print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f4f863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.16\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = images.view(-1, 28*28).requires_grad_()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Total number of labels\n",
    "    total += labels.size(0)\n",
    "\n",
    "    # Total correct predictions\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "accuracy = 100 * (correct.item() / total)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87ed61",
   "metadata": {},
   "source": [
    "> Saving PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cce3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3791e",
   "metadata": {},
   "source": [
    "> CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14687db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8417850732803345. Accuracy: 67.38\n",
      "Iteration: 1000. Loss: 1.5717761516571045. Accuracy: 75.22\n",
      "Iteration: 1500. Loss: 1.345556378364563. Accuracy: 78.68\n",
      "Iteration: 2000. Loss: 1.1935166120529175. Accuracy: 80.74\n",
      "Iteration: 2500. Loss: 1.1703860759735107. Accuracy: 82.02\n",
      "Iteration: 3000. Loss: 0.9963839054107666. Accuracy: 82.66\n"
     ]
    }
   ],
   "source": [
    "# The usual 7-step process, getting repetitive by now which we like.\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # 100 x 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                # 100 x 1\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
